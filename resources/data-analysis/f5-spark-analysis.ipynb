{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F5.news Trending News - Machine Learning Exploration\n",
    "\n",
    "- News Article Sentiment\n",
    "- Predict Trending Topics\n",
    "- Topic Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U \"pymongo[srv]\" mlflow pyspark hvac python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import hvac\n",
    "import mlflow\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Vault for Mongo connection values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Failed to connect to HashiVault\n"
     ]
    }
   ],
   "source": [
    "client = hvac.Client(\n",
    "    url=os.environ.get('VAULT_ADDR'),\n",
    "    token=os.environ.get('VAULT_TOKEN'),\n",
    ")\n",
    "\n",
    "print(client.is_authenticated())\n",
    "\n",
    "if client.is_authenticated():\n",
    "    try:\n",
    "        secret_resp = client.secrets.kv.v2.read_secret_version(\n",
    "            mount_point='kv', \n",
    "            path='f5.news', \n",
    "            raise_on_deleted_version=False\n",
    "        )\n",
    "        \n",
    "        if secret_resp['data'] is not None:\n",
    "            secret_values = secret_resp['data']['data']\n",
    "            for secret, value in secret_values.items():\n",
    "                os.environ[str(secret)] = str(value)\n",
    "        else:\n",
    "            print(\"The secret does not exist.\")\n",
    "    except hvac.exceptions.InvalidPath:\n",
    "        print(\"The path is invalid or the permission is denied.\")\n",
    "    except hvac.exceptions.Forbidden:\n",
    "        print(\"The permission is denied.\")\n",
    "    except hvac.exceptions.VaultError as e:\n",
    "        print(f\"Vault error occurred: {e}\")\n",
    "else:\n",
    "    print(\"Failed to connect to HashiVault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "URI = os.environ['mongo_uri']\n",
    "DATABASE = os.environ['database']\n",
    "COLLECTION = os.environ['collection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull F5 records using pymongo client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB...\n",
      "Mongo documents loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new client and connect to the server\n",
    "client = MongoClient(URI, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Successfully connected to MongoDB...\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    database = client[DATABASE]\n",
    "    collection = database[COLLECTION]\n",
    "\n",
    "    # Query all documents in the collection\n",
    "    documents = collection.find({\"sub\": \"politics\"}).sort({\"upvoteCount\": -1, \"fetchedAt\": -1})\n",
    "\n",
    "    if(DEBUG == True):\n",
    "        # Iterate over the cursor to access the documents\n",
    "        for doc in documents:\n",
    "            print(doc[\"title\"])\n",
    "            print(doc[\"fetchedAt\"])\n",
    "            print(doc[\"upvoteCount\"], \"upvotes\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"Mongo documents loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Spark and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from MongoDB!\n",
      "root\n",
      " |-- __v: integer (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- commentCount: integer (nullable = true)\n",
      " |-- commentLink: string (nullable = true)\n",
      " |-- created_utc: integer (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- fetchedAt: timestamp (nullable = true)\n",
      " |-- is_self: boolean (nullable = true)\n",
      " |-- is_video: boolean (nullable = true)\n",
      " |-- media: struct (nullable = true)\n",
      " |    |-- event_id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- post_hint: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- selftext_html: string (nullable = true)\n",
      " |-- sub: string (nullable = true)\n",
      " |-- thumbnail: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- upvoteCount: integer (nullable = true)\n",
      " |-- upvote_ratio: double (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n",
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|__v|_id                       |author        |commentCount|commentLink                                                                 |created_utc|domain          |fetchedAt              |is_self|is_video|media|post_hint|selftext|selftext_html|sub |thumbnail|title                                                                                           |upvoteCount|upvote_ratio|url                                                                                                                                     |\n",
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0  |{65e0f6047e56c7a1e4ab5396}|nirad         |1066        |/r/news/comments/1b37ga3/donald_trump_found_to_have_fraudulently_boosted/   |1709231372 |thenational.scot|2024-03-01 23:44:19.914|false  |false   |NULL |NULL     |        |NULL         |news|         |Donald Trump found to have fraudulently boosted value of Scots homes by up to Â£200m             |21842      |0.91        |https://www.thenational.scot/news/24143657.donald-trump-found-fraudulently-boosted-value-scots-homes-200m/                              |\n",
      "|0  |{65e112247e56c7a1e4036388}|sue_me_please |170         |/r/news/comments/1b3effu/lgbtq_group_sues_to_block_texas_ag_paxtons/        |1709247994 |keranews.org    |2024-03-01 23:39:19.997|false  |false   |NULL |NULL     |        |NULL         |news|         |LGBTQ group sues to block Texas AG Paxton's request for records about transgender children      |4610       |0.93        |https://www.keranews.org/texas-news/2024-02-29/lgbtq-group-sues-to-block-texas-ag-paxtons-request-for-records-about-transgender-children|\n",
      "|0  |{65e12f707e56c7a1e45d8409}|BarKnight     |411         |/r/news/comments/1b3hbvu/michigan_communities_will_share_a_record_87m_in/   |1709255499 |freep.com       |2024-03-02 00:24:22.398|false  |false   |NULL |NULL     |        |NULL         |news|         |Michigan communities will share a record $87M in marijuana tax revenue                          |6265       |0.97        |https://www.freep.com/story/news/marijuana/2024/02/29/michigan-communities-will-share-a-record-87m-in-marijuana-tax-revenue/72792733007/|\n",
      "|0  |{65e158747e56c7a1e4d232f4}|Silent_killa42|1003        |/r/news/comments/1b3l1u6/irs_launches_crackdown_on_125000_wealthy_nonfilers/|1709266176 |apnews.com      |2024-03-02 14:34:20.029|false  |false   |NULL |NULL     |        |NULL         |news|         |IRS launches crackdown on 125,000 wealthy ânon-filersâ                                          |20920      |0.96        |https://apnews.com/article/irs-tax-season-audit-back-taxes-77c891313f5233366fbe4f6fb5d896e8                                             |\n",
      "|0  |{65e161d47e56c7a1e4ecc798}|jayRIOT       |252         |/r/news/comments/1b3lslv/blockbuster_california_storm_to_deliver_crushing/  |1709268589 |cnn.com         |2024-03-02 00:24:22.398|false  |false   |NULL |NULL     |        |NULL         |news|         |Blockbuster California storm to deliver crushing blow of 10 feet of snow and blizzard conditions|2888       |0.97        |https://www.cnn.com/2024/02/29/weather/california-storm-snow-blizzard-climate/index.html                                                |\n",
      "+---+--------------------------+--------------+------------+----------------------------------------------------------------------------+-----------+----------------+-----------------------+-------+--------+-----+---------+--------+-------------+----+---------+------------------------------------------------------------------------------------------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"param1\", \"value1\")\n",
    "    mlflow.log_param(\"param2\", \"value2\")\n",
    "    \n",
    "    try:\n",
    "         # Create a SparkSession\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"F5news\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Load data from MongoDB into a DataFrame\n",
    "        df = spark.read.format(\"mongo\").option(\"uri\", URI).option(\"database\", DATABASE).option(\"collection\", COLLECTION).load()\n",
    "        print(\"Data loaded successfully from MongoDB!\")\n",
    "        \n",
    "        # Show loaded data\n",
    "        df.printSchema()\n",
    "        df.show(5,truncate=False)\n",
    "    except Exception as e:\n",
    "        # Error occurred during data loading or model training\n",
    "        print(\"Error:\", str(e))\n",
    "\n",
    "        # Stop SparkSession\n",
    "        spark.stop()\n",
    "\n",
    "        # End MLflow run\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out Recent Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Loaded: 4411\n",
      "Total Filtered Documents: 3900\n"
     ]
    }
   ],
   "source": [
    "# Get document initial count\n",
    "print('Documents Loaded:', df.count())\n",
    "\n",
    "# Convert to SQL for familiar data query ability\n",
    "df.createOrReplaceTempView(\"temp\")\n",
    "df = spark.sql(\"SELECT title, upvoteCount, fetchedAt from temp\") \n",
    "\n",
    "# Filter out new posts\n",
    "oneDayAgo = d = datetime.today() - timedelta(days=1)\n",
    "df = df.filter(df.fetchedAt < oneDayAgo)\n",
    "print('Total Filtered Documents:', df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketize by Upvote Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|     bucket|count|\n",
      "+-----------+-----+\n",
      "|      0-999| 3090|\n",
      "|  1000-4999|  521|\n",
      "|  5000-9999|  172|\n",
      "|10000-24999|  102|\n",
      "|25000-49000|   15|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def upvoteCategorizer(upvotes):\n",
    "    if upvotes < 1000:\n",
    "        return \"0-999\"\n",
    "    if upvotes < 5000:\n",
    "        return \"1000-4999\"\n",
    "    if upvotes < 10000:\n",
    "        return \"5000-9999\"\n",
    "    elif upvotes < 25000:\n",
    "        return \"10000-24999\"\n",
    "    elif upvotes < 50000:\n",
    "        return \"25000-49000\"\n",
    "    else: \n",
    "        return \"50000+\"\n",
    "    \n",
    "bucket_udf = udf(upvoteCategorizer, StringType() )\n",
    "df = df.withColumn(\"bucket\", bucket_udf(\"upvoteCount\"))\n",
    "df.groupBy(\"bucket\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview random sample of bucketized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+---------+\n",
      "|               title|upvoteCount|           fetchedAt|   bucket|\n",
      "+--------------------+-----------+--------------------+---------+\n",
      "|CCTV footage of p...|          7|2024-03-09 06:49:...|    0-999|\n",
      "|Trump endorses Ma...|          0|2024-03-03 23:49:...|    0-999|\n",
      "|The DOJ has opene...|       8905|2024-03-12 11:09:...|5000-9999|\n",
      "|Ukrainians to pay...|         13|2024-03-06 21:44:...|    0-999|\n",
      "|I love President ...|          0|2024-03-05 10:49:...|    0-999|\n",
      "|AOC confronted by...|          0|2024-03-05 15:24:...|    0-999|\n",
      "|Russian volunteer...|         84|2024-03-12 11:29:...|    0-999|\n",
      "|Nikki Haley will ...|         23|2024-03-06 12:59:...|    0-999|\n",
      "|\"Like someone pul...|       3913|2024-03-02 23:14:...|1000-4999|\n",
      "|Federal judiciary...|        130|2024-03-12 21:04:...|    0-999|\n",
      "|George Santos pla...|         15|2024-03-08 01:44:...|    0-999|\n",
      "|âLook me in the e...|         45|2024-03-01 23:39:...|    0-999|\n",
      "|Biden, Trump laun...|         13|2024-03-09 13:34:...|    0-999|\n",
      "|House panel unani...|         33|2024-03-09 12:19:...|    0-999|\n",
      "|China protests In...|          6|2024-03-12 12:14:...|    0-999|\n",
      "|Democrats Have an...|         16|2024-03-08 00:39:...|    0-999|\n",
      "|China tightens gr...|          6|2024-03-10 08:19:...|    0-999|\n",
      "|A Promising Air F...|         51|2024-03-07 02:49:...|    0-999|\n",
      "|Russia says Weste...|          9|2024-03-05 12:54:...|    0-999|\n",
      "|Delaware legislat...|         30|2024-03-06 18:19:...|    0-999|\n",
      "+--------------------+-----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_count = 20\n",
    "pandas_random_sample = df.toPandas().sample(n=sample_count) # Convert to pandas dataframe to take sample\n",
    "pyspark_random_sample = spark.createDataFrame(pandas_random_sample) # Convert back to pyspark dataframe\n",
    "pyspark_random_sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data prep pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression Tokenizer\n",
    "# - Breaks title into array of words via regex\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"title\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# Stop Words Remover\n",
    "# - Removes undesireable words from ouput of Regex Tokenizer\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] # TODO: Update stopwords to match dataset\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "# Bag of Words Counter\n",
    "# - Creates vector representation of the array of words extracted from original title string\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=30000, minDF=5)\n",
    "\n",
    "# Create label\n",
    "# - Maps all possible values in bucket columns to numeric values (their index position in an array of unique bucket values)\n",
    "label_stringIdx = StringIndexer(inputCol = \"bucket\", outputCol = \"label\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble data prep pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline using previously prepared steps\n",
    "# - this is where we get our 'features' columns from. We split titles to words, remove the words we don't want, then vectorize the resulting array of words, then label based on bucket col\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the data prep pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|               title|upvoteCount|           fetchedAt|bucket|               words|            filtered|            features|label|\n",
      "+--------------------+-----------+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|Ultra-conservativ...|         35|2024-03-01 22:09:...| 0-999|[ultra, conservat...|[ultra, conservat...|(1782,[4,35,496,5...|  0.0|\n",
      "|Joe Biden has rai...|         49|2024-03-01 22:14:...| 0-999|[joe, biden, has,...|[joe, biden, has,...|(1782,[2,5,8,12,1...|  0.0|\n",
      "|Oregon takes mass...|          4|2024-03-01 22:14:...| 0-999|[oregon, takes, m...|[oregon, takes, m...|(1782,[376,396,53...|  0.0|\n",
      "|DC Circuit tosses...|         21|2024-03-01 22:19:...| 0-999|[dc, circuit, tos...|[dc, circuit, tos...|(1782,[0,1,3,4,6,...|  0.0|\n",
      "|Shervin Hajipour:...|         34|2024-03-01 22:19:...| 0-999|[shervin, hajipou...|[shervin, hajipou...|(1782,[0,9,11,14,...|  0.0|\n",
      "+--------------------+-----------+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "# Preview dataset before training\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 162:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lr_model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----------+--------------------------------------------------+-----+----------+\n",
      "|                                             title|     bucket|                                       probability|label|prediction|\n",
      "+--------------------------------------------------+-----------+--------------------------------------------------+-----+----------+\n",
      "|Nasrallah's grandson killed in IDF targeted att...|  1000-4999|[0.4645782027380458,0.47104484094916904,0.03935...|  1.0|       1.0|\n",
      "|Pope criticised for saying Ukraine should ârais...|10000-24999|[0.4490831147920505,0.4919561890163278,0.034715...|  3.0|       1.0|\n",
      "|How clean is the dirt on Hunter Biden? A key Re...|      0-999|[0.4321101142891121,0.4759676440038168,0.068277...|  0.0|       1.0|\n",
      "|Army intelligence analyst charged with selling ...|  1000-4999|[0.4040768731806385,0.4951014326298967,0.063961...|  1.0|       1.0|\n",
      "|Taylor Swift can teach us all a lesson in how d...|      0-999|[0.39821273325620327,0.39925304449626964,0.0951...|  0.0|       1.0|\n",
      "|\"Department of Life\": Trump allies plot abortio...|  1000-4999|[0.35547493373900046,0.5317836100564194,0.06098...|  1.0|       1.0|\n",
      "|A former Boeing manager turned whistleblower ha...|  5000-9999|[0.3457249721774329,0.595458222468971,0.0330944...|  2.0|       1.0|\n",
      "|   Swedish flag is now raised at NATO headquarters|  1000-4999|[0.3372933040521534,0.5218820095864416,0.105066...|  1.0|       1.0|\n",
      "|Education Department to open investigation into...|      0-999|[0.3256691249284586,0.6056222931071362,0.049841...|  0.0|       1.0|\n",
      "|Trump is degenerating before our eyes â MAGA vo...|  5000-9999|[0.31620894070951355,0.5419929289218705,0.02850...|  2.0|       1.0|\n",
      "|Joe Biden Says Thereâs a Place for Nikki Haley ...|  1000-4999|[0.2476615817313917,0.3071139151003214,0.149148...|  1.0|       1.0|\n",
      "|IDF accuses additional UNRWA officials of Oct. ...|      0-999|[0.23858302804098722,0.6757151741098408,0.06203...|  0.0|       1.0|\n",
      "|Police stop boy, 11, driving BMW towing caravan...|      0-999|[0.22477451370188853,0.7118177673361746,0.02529...|  0.0|       1.0|\n",
      "|Yet another Republican senator says he wonât en...|  1000-4999|[0.18150536930029643,0.7230778556441938,0.06629...|  1.0|       1.0|\n",
      "|German âPlotâ to Bomb Crimean Bridge Sparks Mos...|  5000-9999|[0.16026331725810009,0.5668827428300304,0.21831...|  2.0|       1.0|\n",
      "+--------------------------------------------------+-----------+--------------------------------------------------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 201:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Make Predictions for entire test data set\n",
    "predictions = lr_model.transform(testData)\n",
    "\n",
    "# Show a few predictions\n",
    "# - change filter params such as prediction == 1\n",
    "predictions.filter(predictions['prediction'] == 1).select(\"title\",\"bucket\",\"probability\",\"label\",\"prediction\")\\\n",
    ".orderBy(\"probability\", ascending=False).show(n = 20, truncate = 50)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = predictions.selectExpr(\"sqrt(avg(pow(upvoteCount - prediction, 2))) as RMSE\").collect()[0][\"RMSE\"]\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data:\", rmse) # TODO: Determine output label\n",
    "\n",
    "# Calculate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "lrAccuracy = evaluator.evaluate(predictions)\n",
    "print(lrAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Final Model Metrics to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f29708739d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log metrics\n",
    "mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "# Log trained model\n",
    "mlflow.spark.log_model(lr_model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Out Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkSession\n",
    "spark.stop()\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
