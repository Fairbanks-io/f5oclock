{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F5.news Trending News - Machine Learning Exploration\n",
    "\n",
    "- News Article Sentiment\n",
    "- Predict Trending Topics\n",
    "- Topic Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U boto3 hvac mlflow numpy \"pyspark==3.5.0\" python-dotenv \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hvac\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import Bucketizer, StringIndexer, VectorAssembler, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Vault for Mongo Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = hvac.Client(\n",
    "    url=os.environ.get('VAULT_ADDR'),\n",
    "    token=os.environ.get('VAULT_TOKEN'),\n",
    ")\n",
    "\n",
    "print(client.is_authenticated())\n",
    "\n",
    "if client.is_authenticated():\n",
    "    try:\n",
    "        secret_resp = client.secrets.kv.v2.read_secret_version(\n",
    "            mount_point='kv', \n",
    "            path='f5.news', \n",
    "            raise_on_deleted_version=False\n",
    "        )\n",
    "        \n",
    "        if secret_resp['data'] is not None:\n",
    "            secret_values = secret_resp['data']['data']\n",
    "            for secret, value in secret_values.items():\n",
    "                os.environ[str(secret)] = str(value)\n",
    "        else:\n",
    "            print(\"The secret does not exist.\")\n",
    "    except hvac.exceptions.InvalidPath:\n",
    "        print(\"The path is invalid or the permission is denied.\")\n",
    "    except hvac.exceptions.Forbidden:\n",
    "        print(\"The permission is denied.\")\n",
    "    except hvac.exceptions.VaultError as e:\n",
    "        print(f\"Vault error occurred: {e}\")\n",
    "else:\n",
    "    print(\"Failed to connect to HashiVault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "DEBUG = False\n",
    "MODE = \"local\" # Supported -- local OR cluster\n",
    "REG_PARAM_VALUE = 0.1 # Experimenting with this value can improve final accuracy\n",
    "MAX_ITER = 20\n",
    "DATASET_SPLIT = [0.9, 0.1] # Portion of data to split between training and test datasets\n",
    "SAMPLE_TITLE_1 = \"Trump Says Some Migrants Are ‘Not People’ and Predicts a ‘Blood Bath’ if He Loses\"\n",
    "SAMPLE_TITLE_2 = \"California Insurance Commissioner Ricardo Lara responds after State Farm announces it will not renew thousands of policies - ABC7 Los Angeles\"\n",
    "SAMPLE_TITLE_3 = \"Oklahoma students walk out after trans student's death to protest bullying policies\"\n",
    "\n",
    "# Spark\n",
    "SPARK_MASTER = \"spark://localhost:7077\"\n",
    "SPARK_MEMORY = \"4g\"\n",
    "os.environ[\"PYSPARK_PIN_THREAD\"] = \"false\" # TODO: Move to .env\n",
    "\n",
    "# Mongo\n",
    "URI = os.environ['mongo_uri']\n",
    "DATABASE = os.environ['database']\n",
    "COLLECTION = os.environ['collection']\n",
    "\n",
    "# MLflow\n",
    "MLFLOW_API = \"http://localhost:5000\"\n",
    "MODEL_NAME = \"f5news_upvote_bucket_prediction\"\n",
    "EXPERIMENT_NAME = \"f5news_upvote_bucket_prediction\"\n",
    "\n",
    "# Minio S3\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://localhost:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"minio\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"minio123\" # TODO: Move all of these to .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull F5 records using pymongo client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    # Create a new client and connect to the MongoDB server\n",
    "    client = MongoClient(URI, server_api=ServerApi('1'))\n",
    "\n",
    "    # Send a ping to confirm a successful connection\n",
    "    try:\n",
    "        client.admin.command('ping')\n",
    "        print(\"Successfully connected to MongoDB...\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        database = client[DATABASE]\n",
    "        collection = database[COLLECTION]\n",
    "\n",
    "        # Query all documents in the collection\n",
    "        documents = collection.find({\"sub\": \"politics\"}).sort({\"upvoteCount\": -1, \"fetchedAt\": -1})\n",
    "\n",
    "        if(DEBUG == True):\n",
    "            # Iterate over the cursor to access the documents\n",
    "            for doc in documents:\n",
    "                print(doc[\"title\"])\n",
    "                print(doc[\"fetchedAt\"])\n",
    "                print(doc[\"upvoteCount\"], \"upvotes\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"Mongo documents loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup MLflow runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_run_name = None\n",
    "global_run_id = None\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Set MLflow configs\n",
    "mlflow.set_tracking_uri(MLFLOW_API)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "def start_mlflow_run(run_name: str = None):\n",
    "    global global_run_name, global_run_id, start_time\n",
    "    if run_name is None:\n",
    "        run_name = start_time\n",
    "    else:\n",
    "        run_name = run_name + start_time\n",
    "    global_run_name = run_name\n",
    "    run = mlflow.start_run(run_name=run_name, description=EXPERIMENT_NAME)\n",
    "    global_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLflow Run Instance\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "start_mlflow_run()\n",
    "\n",
    "# Log parameters\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "mlflow.log_param(\"start_time\", start_time)\n",
    "\n",
    "try:\n",
    "    if MODE == \"local\":\n",
    "        print(\"Starting Spark in local mode\")\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"F5news\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.mlflow:mlflow-spark:2.8.1\") \\\n",
    "            .getOrCreate()\n",
    "    elif MODE == \"cluster\":\n",
    "        print(\"Starting Spark in cluster mode\")\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"F5news\") \\\n",
    "            .master(SPARK_MASTER) \\\n",
    "            .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.mlflow:mlflow-spark:2.8.1\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    # Setup Spark AutoLog\n",
    "    mlflow.autolog()\n",
    "\n",
    "    # Get Spark version\n",
    "    spark_version = spark.version\n",
    "    print(\"Spark Version:\", spark_version)\n",
    "\n",
    "    # Check if the master URL indicates local mode or a specific cluster mode\n",
    "    sc = spark.sparkContext\n",
    "    master_url = sc.master\n",
    "    \n",
    "    if \"local\" and not \"localhost\" in master_url:\n",
    "        print(\"PySpark is running in local mode.\")\n",
    "    else:\n",
    "        print(\"PySpark is running in cluster mode with master URL:\", master_url)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", str(e))\n",
    "\n",
    "    # Stop SparkSession\n",
    "    spark.stop()\n",
    "\n",
    "    # End MLflow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MongoDB as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Schema\n",
    "schema = StructType([\n",
    "    StructField(\"title\", StringType(), nullable=True), # model input\n",
    "    StructField(\"upvoteCount\", DoubleType(), nullable=True), # used to bucketize for training\n",
    "    StructField(\"fetchedAt\", TimestampType(), nullable=True) # used to filter recent events\n",
    "])\n",
    "\n",
    "# Load data from MongoDB into a DataFrame\n",
    "df = spark.read \\\n",
    "    .format(\"mongo\") \\\n",
    "    .option(\"uri\", URI) \\\n",
    "    .option(\"database\", DATABASE) \\\n",
    "    .option(\"collection\", COLLECTION) \\\n",
    "    .schema(schema) \\\n",
    "    .load()\n",
    "\n",
    "print(\"Data loaded successfully from MongoDB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out Recent Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document initial count\n",
    "print('Documents Loaded:', df.count())\n",
    "mlflow.log_param(\"loaded_documents\", df.count())\n",
    "\n",
    "# Filter out new posts\n",
    "oneDayAgo = d = datetime.today() - timedelta(days=1)\n",
    "df = df.filter(df.fetchedAt < oneDayAgo)\n",
    "print('Total Filtered Documents:', df.count())\n",
    "\n",
    "mlflow.log_param(\"filtered_documents\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketize Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketizer = Bucketizer(splits=[0, 1000, 5000, 10000, 25000, 50000, float('inf')], inputCol=\"upvoteCount\", outputCol=\"bucket\")\n",
    "df = bucketizer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview a Random Sample of Bucketized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sample_count = 10\n",
    "    pandas_random_sample = df.toPandas().sample(n=sample_count) # Convert to pandas dataframe to take sample\n",
    "    pyspark_random_sample = spark.createDataFrame(pandas_random_sample) # Convert back to pyspark dataframe\n",
    "    pyspark_random_sample.show()\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('upvoteCount')\n",
    "df.drop('fetchedAt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df.randomSplit(DATASET_SPLIT, seed = 123456)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "\n",
    "mlflow.log_metric(\"trainingData\", trainingData.count())\n",
    "mlflow.log_metric(\"testData\", testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model Pipeline Steps\n",
    "\n",
    "- **Regular Expression Tokenizer**: Breaks title into array of words via regex\n",
    "- **Stop Words Remover**: Removes undesireable words from Regex Tokenizer output\n",
    "- **Bag of Words Counter**: Creates vector representation of the array of words extracted from original title string\n",
    "- **Logistic Regression**: Trains logistic regression to classify 'bucket' based on the features returned by 'Bag of words' counter/features column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"title\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# StopWordsRemover\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"reddit\",\"subreddit\"] # TODO: Update stopwords to match dataset\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "# CountVectorizer\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=30000, minDF=5)\n",
    "\n",
    "# Init linear regression model with column names\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"bucket\")\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "# paramGrid = (\n",
    "#     ParamGridBuilder()\n",
    "#     .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "#     .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#     .addGrid(lr.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#     .build()\n",
    "# )\n",
    "\n",
    "# define evaluator for cross validator\n",
    "# evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "# cv = CrossValidator(\n",
    "#    estimator=lr, \\\n",
    "#    estimatorParamMaps=paramGrid, \\\n",
    "#    evaluator=evaluator, \\\n",
    "#    numFolds=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Model Pipeline\n",
    "\n",
    "Creates the `features` columns. We split titles to words, remove the words we don't want, vectorize the resulting array of words, then label based on bucket column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData) # This step is what actually does the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions for entire test data set\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Show a few predictions\n",
    "# - change filter params such as prediction == 1 # TODO: Document what this does\n",
    "if DEBUG:\n",
    "    display(predictions.select(\"title\",\"bucket\",\"probability\",\"prediction\",\"features\").orderBy(\"probability\", ascending=False).toPandas().sample(n=10))\n",
    "\n",
    "# Calculate & Log RMSE\n",
    "rmse = predictions.selectExpr(\"sqrt(avg(pow(bucket - prediction, 2))) as RMSE\").collect()[0][\"RMSE\"]\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data:\", rmse) # TODO: Determine output label\n",
    "mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "# Calculate & Log Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"bucket\")\n",
    "lr_accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Logistical Regression Accuracy:\", lr_accuracy)\n",
    "mlflow.log_metric(\"lr_accuracy\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Final Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model = model, \n",
    "        artifact_path = \"model\",\n",
    "    #    signature = signature,\n",
    "        registered_model_name = \"f5news_upvote_bucket_prediction\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"[Warning] Unable to save the model to MLflow: {e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Final Model to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    top_level_dir = \"models\"\n",
    "    os.makedirs(top_level_dir, exist_ok=True)\n",
    "\n",
    "    model_dir = os.path.join(top_level_dir, EXPERIMENT_NAME)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model.save(os.path.join(model_dir, start_time))\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the model to disk: {e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testInput = spark.createDataFrame([\n",
    "    {'title': SAMPLE_TITLE_1},\n",
    "    {'title': SAMPLE_TITLE_2},\n",
    "    {'title': SAMPLE_TITLE_3}\n",
    "])\n",
    "\n",
    "testInput.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model & Make Predictions\n",
    "\n",
    "- **Bucket 0**: 0 - 999 upvotes\n",
    "- **Bucket 1**: 1,000 - 4,999 upvotes\n",
    "- **Bucket 2**: 5,000 - 9,999 upvotes\n",
    "- **Bucket 3**: 10,000 - 24,999 upvotes\n",
    "- **Bucket 4**: 25,000 - 49,999 upvotes\n",
    "- **Bucket 5**: > 50,000 upvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.spark.load_model(f'runs:/{global_run_id}/model') # global_run_id is set by when an MLflow run is initiated\n",
    "\n",
    "predictions = model.transform(testInput)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_scores = predictions.select(\"probability\").rdd.map(lambda x: x[0][1]).collect()\n",
    "formatted_scores = [\"{:.2f}%\".format(score * 100) for score in confidence_scores]\n",
    "\n",
    "print(formatted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Out Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkSession\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
